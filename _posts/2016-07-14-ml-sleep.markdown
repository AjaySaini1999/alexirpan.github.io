---
layout: post
title:  "Machine Learning Workaholism"
date:   2016-07-15 00:55:00 -0700
---

Machine learning is the study of algorithms that let a computer
learn insights from data in a semi-autonomous way.

Machine learning *research* is the process by which researchers
get addicted to gambling their time in the name of improved
results.

\*\*\*
{: .centered }

Despite its foundations in math and statistics, ML is mostly an
experimental science.

That's not saying there's no theory. There's
plenty of theory. A short list: multi-armed bandits, contextual bandits,
non-convex optimization, directed graphical models,
and Markov random fields. The proofs are there, if you look for them.
I'm also not saying there's no place for theory. Not everyone wants
to spend the time to learn why their algorithm is guaranteed to
converge, but everyone wants the proof to exist.

However, in the applications-driven domains that drive AI hype,
people care about results first, theoretical justification second.
That means a lot of heuristics. Often, those heuristics are bound together
in an unsatisfying way that works empirically, but has very little
founding theoretically.

How do we discover those heuristics? Well, by the scientific method.

1. Make hypothesis.
2. Design an experiment to test that hypothesis.
3. Implement and run the experiment.
4. Interpret the analytics.
5. Refine the hypothesis with more informed experiment designs.
6. Repeat until enlightenment.

In machine learning, hypotheses are promising algorithms,
and experiments are benchmarks of those algorithms.

Hey, what's the issue? Just run experiments, until something works!

Well, gather round. I've got a whole plate of beef to share.

\*\*\*
{: .centered }

By and large, ML algorithms are both probabilistic and incredibly
customizable. Empirically, probabilistic approaches work the best on large
datasets, and currently, datasets are very very large. (Big Data is a buzz
word that I've grown to dislike, so I avoid using it.)

Their customizability means you have to try many different
settings to get good performance,
Have you tried tweaking your hyperparameters?
Whitening your data? Using a different optimization algorithm?
Making your model simpler? Making your model more complex? Using batch norm?
Unfortunately, standard practice in ML is to publish the one setting that
worked, and none of the settings that failed. This would be insane in other
fields, but in ML, it's just how things are.

It doesn't help that the difference between
"plausible idea that will work" and "plausible idea that won't" is basically
zero. It also doesn't help that beauty of an idea is basically uncorrelated
with its real-world performance.
Here's a conversation I overheard once, between a computer vision
professor and one of his students.

> Student: It doesn't work.
>
> Professor: No! It doesn't work? The theory's too beautiful for it not
> to work!
>
> Student: I know. The argument is very elegant, but it doesn't work in practice.
> Not even on [Lenna](https://en.wikipedia.org/wiki/Lenna).
>
> Professor: (in a half-joking tone) Maybe if we run it on a million images,
> in parallel, it'll magically start working.
>
> Student: If it doesn't work on a single image of Lenna, it's not going to work
> on a million copies of Lenna.
>
> Professor: Ahhhh, I suppose so. What a shame.

I feel their pain.

After training enough machine learning models, you gain an intuition for which
knobs are most important to turn, but it never quite hits the level of guaranteed
success. I like to joke that one day, the theorists will catch up and recommend
an approach for reasons better than "it works empirically", but I don't think
it'll happen anytime soon. The theory is very hard.

(What theory *has* done is produce the [no free lunch theorem](http://www.no-free-lunch.org/).
Informally, it says that no algorithm can beat every other algorithm on
every problem, meaning every problem must have a different optimal solution.
Having a formal proof of the hopelessness of the problem is nice.)

\*\*\*
{: .centered }

I still haven't explained why machine learning research can easily take over
your life.

Well, I suppose I have, in a roundabout way. ML experiments can be very random
and very arbitrary, working or failing at a drop of a hat. Not even the legends
in the field can get away with avoiding hyperparameter tuning. It has to be
done if you want good performance.

It feels like one huge casino. You pull the lever of the slot machine, and
hope it works. Sometimes, it does. Or somebody tells you the slot machine
hasn't worked in 10 years and you should try the new slot machine everyone's
excited about. Or they share a schematic of part of the slot machine's
design, discovered through trial and error by many people before you.
We understand many things, but the slot machine's still a slot machine,
randomness and all. And worse, it's a slot machine where your job or
funding or graduation is on the line.

In the game of machine learning, you get lucky, or try
so many times you *have* to get lucky. The only way to guarantee success
is to do the latter.

Just Work by, I don't know, sacrificing a goat under the light of the full moon,
we'd do it in a heartbeat. Because if machine learning algorithms Just Worked,
it would definitely make up for killing one goat.

In the game of machine learning, you get lucky on the first try, or try
so many times you *have* to get lucky. And the only way to succeed is to
do the latter.

And that means experiments. Tons and tons of experiments. It doesn't help that
the best time to run experiments is when you're about to take a break.
Going out for lunch? Start an experiment, see how it's doing when
you get back. Heading out for the day? Run an experiment overnight, check the
results tomorrow morning. Don't want to work over the weekend? Well, your computer
won't mind. We're in a lucky regime where we can mostly run our experiments
unattended, which is great, until you keep working through the night because
your code is broken and you really want to run something overnight.
(This is how people promise to themselves they'll leave by 7 PM, and end up
staying until midnight.)

It's the kind of mindset that sucks in people who have workaholic mindsets.
You don't *have* to run an experiment every night. I'm just saying, if this
code isn't fixed by tonight, you're going to miss out on so much delicious
computation time. Don't come crawling back to me if you fail because you
didn't throw enough darts at the dartboard...

I've been trying to avoid falling into that hole, with strictly enforced
work-life balance. I'd like to have time for other things, like blogging.
Or more importantly, video games. (No, but seriously, I am sorry I
haven't been blogging very often.)

Until then, here's us. On the raggedy edge.

