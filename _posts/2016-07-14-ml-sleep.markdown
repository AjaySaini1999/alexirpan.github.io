---
layout: post
title:  "TITLE PLEASE"
date:   2016-07-15 00:55:00 -0700
---

Machine learning is the study of algorithms that let a computer
learn insights from data in a semi-autonomous way.

Machine learning *research* is the process by which programmers
can work themselves to death in the name of optimally using human time
and computer time.

Let me explain.

\*\*\*
{: .centered }

Despite all the math on the surface, machine learning is a largely
experimental field. That's not saying there's no theory. There's
plenty of theory. Multi-armed bandits, contextual bandits, convex
optimization, non-convex optimization, directed graphical models,
Markov random fields: if you look, the theory will be there.

However, the flashy results like speech recognition and translation (or
in other words, the results that make industry pour mountains of money
into ML) are relentlessly experimentalist.
The theory is important, but you can get surprisingly far without it.

Like all experimentalist fields, the way to ensure good results is to
put in the hours. Here's the experiment loop, which holds across every field.

1. Design an experiment.
2. Implement and run the experiment.
3. Interpret the analytics.
4. Update the experiment design.
5. Repeat until you have results.

For ML, experiment designs means reading and thinking about state-of-the-art
approaches, and implementation means writing experiment code. Luckily,
ML experiments have turnaround times measured in hours. I hear other fields
have experiments that take weeks, or months.

However, short turnaround times are actually a bit of a curse.
Think of ML experiments as playing a card game.
Almost all ML algorithms are probabilistic in some way, because they've
empirically worked the best. The exact same experiment could work one
time, and fail another time, and this even before hyperparameter tuning.
(This is especially painful for reinforcement learning, a notoriously
brittle set of algorithms. I've heard and lived many fail-to-replicate stories.
A lot of recent advances could be summarized as ways to make the method
converge to good behavior more often.) There's skill, in learning how to
play cards correctly, and people with more skill tend to do better, but
there will always be luck involved. Similarly, over time ML researchers
gain an intuition for when an approach is likely to be fruitful, but whether
it works or whether the theoretical justification translates into
empirical results is still a gambler's game.

If your experiments take months to finish, you carefully plan out every aspect
to give yourself as high a chance of success as possible, because there simply
isn't time to fail too often.

If, on the other hand, you can run several experiments a day, it's a lot easier
to just run several experiments. Machine learning theory lags behind practice,
and even legends in the field have to do lots of tweaking to make
algorithms work.

In the game of machine learning, you get lucky on your first try, or you try
so many times that you *have* to get lucky. Everyone ends up choosing the
second strategy.

Unfortunately, running lots of experiments takes time.
My schedule is ruled by experiments. The best time for a human to run
experiments is when the human needs to go on a break. Going out for lunch?
Start an experiment, see how it's doing in an hour.
Heading out for the day? Run an experiment overnight, check the results
tmorrow morning. Don't want to work over the weekend? Well, your computer
won't mind. Have an experiment you want to run? Of course, you don't
*have* to run an experiment. I'm just saying, if you have a long term experiment,
and don't get the code working by tonight, you'll have to wait an extra
two days to get results because you decided to finish it after the weekend...

I've lost track of how many times I've worked way longer than planned
because I couldn't get my code working. How many times I've spent Friday
nights praying my code would stop crashing, because I needed the weekend
computation time.

Unfortunately, experimentalists produce new algorithms faster than
theorists can formally explain why they work so well empirically.
