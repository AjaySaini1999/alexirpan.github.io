---
layout: post
title:  "Reinforcement Learning Doesn't Work Yet"
date:   2017-08-05 01:31:00 -0700
---

*Colored by personal experience. It's been about 6 months since I implemented RL myself, but from what I hear, not a lot has changed.*

If you ask me if reinforcement learning can solve your problem, I'll tell
you it can't, and I think this is correct about 70% of the time.

Reinforcement learning has mountains and mountains of hype behind it. I think
RL certainly deserves a lot of hype, but not as much as it's currently getting,
given how little it can actually do. Hidden behind the beautiful demos is
mountains and mountains of pain, failed experiments, instability, and pure,
nonsensical bullshit.

This is part of why all my AI timelines are fairly long term, by the way.

Okay. Why doesn't RL work?


It's Horribly Unstable
------------------------------------------------------------------------

Karpathy quote.

"I get lunch with people who have been in this field for a few years,
and after a few months I finally got RL to solve a task. Except then it
fails 30% of the time, just cause."

Almost every ML algorithm has hyperparameters, which influence the behavior
of the learning system. Often, these are picked by hand, or by random search.

Supervised learning is stable. If you change the hyperparamters a little bit,
your performance won't change that much. Not all hyperparameters perform that
well, but it's relatively easy to see signs of life. These signs of life are
super important, because they tell you that you're on the right track, and
that it's worth investing more time.

Reinforcement learning, on the other hand, isn't stable at all. It is aggressively,
almost pathologically unstable. It is so bad that it's almost productive to
imagine your computer is a demon that's trying to misinterpret what you're trying
to get it to optimize.

Let me give you an example. When I started working at Brain, one of the first
things I did was to reproduce the results of a continuous RL paper. Specifically,
I was trying to reproduce the paper that introduces Normalized Advantage Function.
Now, as luck would have it, the first author of that paper was interning at
Brain and sitting right next to me.

