---
layout: post
title:  "MIT Mystery Hunt 2020, Part 2"
date:   2020-01-22 03:10:00 -0500
---

Now that
[My Little Pony: Puzzles Are Magic](https://www.puzzlesaremagic.com/) has
wrapped up, I have time to finish my posts about MIT Mystery Hunt 2020. And
only well over a month after Hunt too!


Before Hunt
-------------------------------------------------------------------------

Before MIT Mystery Hunt officially starts, people on our team like trying to
identify hidden Mystery Hunt data before the hunt officially starts. This year,
we had two targets: the emails from Left Out, and the wedding invitations.

Every email we got from Left Out had a different signature. There was "Like Pluto,
Left Out". Another said "Like J in a Playfair Cipher, Left Out". Then there was
"Like a cake in the rain, Left Out". Some people felt this was just Left Out's
gimmick (every signature is about something that's left out), but *maybe*
they were a puzzle, so we kept track of all of them.

When we got all the emails about the overnight situation, I argued this was
weak evidence in favor of the emails being a puzzle. The argument went like this:
if the emails were a puzzle, Left Out would need to know exactly how many
different signatures they needed to send before Hunt. The overnight situation
was a surprise. Therefore, if the emails were a puzzle, they wouldn't have
custom signatures prepared for those emails, and none of the overnight situation
emails had a custom signature.

Someone else pointed out that given the seriousness of the situation, Left Out
wasn't likely to include a jokey signature in those emails, whether or not the
emails were a puzzle. That convinced me the emails weren't a puzzle.

The wedding invitations, on the other hand...

![Wedding invite with lines](/public/mh20-part2/hunt_invite.png)
{: .centered }

We recognized the first invite was a reference to the 2011 MIT Mystery Hunt
invitation, but the second invite looked weirder. Why did the alignment look
a little off center? Why was `WED LOVE YOU TO JOIN US!` missing an apostrophe in
WE'D? And so on.

Last year, our "is this a puzzle" theories were all in a channel named `#innovated-shitposting`.
This year, it was `#wed-love-u-2-shitpost`. The working theory was that "join us"
meant "draw connecting lines", "to" meant "connect the 2s", "love" meant
"connect the hearts in the time", and "you" mean "connect the Us".

So, uh, yeah, that's where all those red lines come from. We also thought it
might have involved folding, so we tried that too.

![Folded invite](/public/mh20-part2/hunt_invite_folded.png)
{: .centered }

As I was boarding my flight to Boston, my position was that the invite was
more-likely-than-not a puzzle (say, 60% chance), but it would come with a shell
that we wouldn't see until Hunt, so until then I wasn't going to try anything.

Meanwhile, two people on teammate made a $20 bet with each other that the emails
would or wouldn't be a puzzle. Neither the emails nor the wedding invite were
a puzzle, and to quote the loser of the bet, "I'm a lot less confident in my
bet now that I've read all the emails, but I'm not going to back down from a
bet I accepted."

The day before hunt was spent socializing and figuring out logistics.
One teammate refreshed [Mystery Hunt Bingo](https://www.alexirpan.com/mystery-hunt-bingo/)
until we got a board that would give a bingo if it had puzzles we wanted to see
in Mystery Hunt. But, was cherry-picking a bingo board ethical?
We discussed it at the social, and Rahul proclaimed "It's *okay* to cheat at bingo".
That was that.


A Tangent About Guessing
------------------------------------------------------------------------------

In the minutes before Hunt, we learned there would be an automatic checker
this year. That's as good a segue as any to talk about guess rates.
As has been said many times elsewhere, teammate is an outlier on submitting
tons of guesses during Mystery Hunt.
Speaking personally (and definitely not for others on the team),
here's why I tend to guess a lot during Hunt.

To me, good puzzle solvers are distinguished
by their ability to correctly generalize from limited data, solve around
mistakes they've made in data collection, and rapidly form and discard hypotheses
about how a puzzle works. More concretely, if you can reliably solve puzzles
from 80% of the clues, it takes 80% of the time per puzzle. Except, in practice,
it works out to *faster* than 80%, because the last 20% of clues are the hardest
ones.
The same principle holds for metapuzzles. If you can solve a
meta from 60% of the feeders, then you get to skip the hardest 40% of that round,
so you may cut your solve time by over half of what you'd spend in a full
100% forward solve.

Because of this, if you want to solve hunts faster, you should
shortcut as much as you can, and that includes making low
confidence guesses that rely on a few of your assumptions being true. The answer
checker is a binary signal between "all your generalizations were correct", or
"at least one of your generalizations was wrong", and although it's a very
low-bandwidth signal, it's a signal that's there. So if the hunt lets you
be more aggressive on guesses, I'll naturally submit a lot of aspirational
guesses.
It's not
personal towards the puzzle author - their puzzle is one of many puzzles
within the cohesive whole that makes up MIT Mystery Hunt. I'm not going to
abuse [OneLook](https://onelook.com/) to solve a cryptic crossword by itself,
but I may abuse OneLook to solve a cryptic crossword that's part of a larger
hunt, once I've gotten through all the clues that look fun.

Did this pay off? Here's a chart of puzzles solved versus guess accuracy of
that team.

![Solves vs acc all teams](/public/mh20-part2/solves_by_acc_all.png)
{: .centered }

The trendline of this chart definitely suggests that teams with lower guess
accuracy solved more puzzles. But hang on a second: there are bunch of
teams with 100% success rate that only solved a few puzzles. Here's the
same plot, if we remove all teams that solved fewer than 10 puzzles.

![Solves vs acc 10 or more](/public/mh20-part2/solves_by_acc_10ormore.png)
{: .centered }

Now, the downward trendline is gone.

My feeling is that yes, teams that guess more did do better this Hunt. However,
the size of that effect is small, and solving speed is still dominated
by general solver ability, and random luck in how fast a team figures out
the metapuzzles.

One other tangent is that I feel a lot of the Puzzlvaria discussion about
guessing is around metapuzzles that were backsolve friendly, and I'm worried
people will think high guess rates come mostly from backsolves. This
isn't true - crazy guesses come from both forward solves and backward solves.

During Puzzles are Magic,
I got curious about forward solve vs backsolve rates. I went through the guess
log, made a list of all answer guesses that looked like backsolves,
and computed forward guesses vs backward guesses for each puzzle.

The results are linked on the full stats page, [here](https://www.puzzlesaremagic.com/hunt_stats/).
Excluding meta puzzles and endgame puzzles (puzzles that couldn't be backsolved),
across the entire hunt there were 4.38 guesses per forward solve, and
5.36 guesses per backward solve.
So yes, backsolves did have more guesses on average that hunt, but it wasn't by
a big margin.


Puzzle Stories
---------------------------------------------------------------------------

I looked around a few puzzles at the beginning, but the one I started first
was Goldilocks. I filled in a few clues, someone else figured out the
mechanic, then I failed to get any more clues and spent my time setting
up indexing in the spreadsheet instead.

The next one I worked on was The Trebuchet, and here it was a similar story.
By the time I got to the puzzle, they had Boggled a few words (the voice
actors from Bolt), and after we realized the ammunition were all puns,
the rest of the walls fell pretty fast. I IDed a few of the shows for
BLOCK OF TNT (wtf SHAQ LIFE is a show??), then started moving letters to
the final wall as we got them. We expected them to slot in automatically,
instead of acting like a drop quote, but I noted we were a few swaps away
from (PHRASE) and someone else finished it from there.

With that puzzle done, I jumped back to Storybook Forest. I briefly looked
at Hackin' the Beanstalk, typing some junk, and noting they looked like
famous algorithms. I opened the sheet for it and saw that every algorithm had
already been IDed. Honestly given the number of CS majors we have I didn't
expect anything else. They tried to figure out indexing for a bit, then
someone threw the authors into nutrimatic and saw [SOURCE FILES](https://nutrimatic.org/?q=%5Bdijkstra%5D%5Bpollard%5D%5Bchudnovsky%5D%5Btarjan%5D%5Beuclid%5D%5Bkadane%5D%5Bfloyd%5D%5Bviterbi%5D%5Bluhn%5D%5Bbresenham%5D%5Bgaleshapley%5D&go=Go) was the first option, and it was right.

With that down, I started looking at Toddler Tilt, which no one had touched yet.
I did a bit of work on it, but had trouble getting the toddlers to fall in the
right order. A few people joined me, I noticed they were figuring it out much
faster than I was, and I decided my time would be better spent on the meta.

Looking through the Storybook Forest meta, I saw there were some tic-tac-toe
theories. We had a lot of 9 letter answers, and the puzzles were arranged in
a 3 x 3 grid. I decided to try extracting the same way as the Dolphin meta
from 20,000 Puzzles Under the Sea, which actually sort of worked, but there
were some weird answers that extracted 2 letters, and there weren't great
ways to use the 11 letter answers. I started looking up tic-tac-toe variants
that might have 11 spots to play, and in the middle of doing so the meta was
solved by someone who didn't believe in any of our tic-tac-toe work.

With that finished, I went back towards The Grand Castle meta.
We had 4 answers in that round, and after some false starts based on
"stately" and "capital", someone discovered the Texas panhandle. I immediately
noted that the panhandle had 26 counties, but out of the final answer of OILMEN,
we had letters LMNO, and that made us think we had an ordering instead.
Writing out the second word of each answer in the panhandle grid gave this.

IMAGE

On seeing this, I proposed that the 2nd words were going to form a cryptic
ending in enumeration SIX. Someone else argued the cryptic would involve
anagramming RACHEL and a possible continuation would be CHARLEMAGNE or
CHARLES, so we called it in, and it was wrong.
We tried a few more variants, but none of those worked either.

We looked at it a bit more, and a 5th feeder answer came in, slotting in
here.

IMAGE

After seeing this, I proposed that we'd actually get *two* cryptics, that
would both share enumeration SIX, and our answer should be a 12-letter
answers. I tried CHARLEMAGNES, plural, and that was wrong. Then someone
found Six Flags Over Texas, which provided an ordering on the clues, and
now that we didn't just have letters LMNO, I was okay with trying the
A-Z idea again, and we solved it.

With those rounds done, it was time to look at Spaceopolis. I watched
our teammates sing karoake, and someone else got the Masked Singer a-ha,
so I decided to do data entry and indexing. The extraction looked bad,
and someone walked around asking for volunteers to solve The Magic
Railway konundrum we'd just unlock. Two of us agreed, and I played a mean
house elf master for about an hour, getting the answer GRACE UNDER FIRE.
With The Magic Railway solved, we saw that Karoake was solved, and opened
the sheet to check what we had missed. It turned out we had extracted the
right letters, and just failed to read it as English.

Sometime shortly after that, we unlocked TEAMWORK TIME: Hat Venn-dor, and
I joined the effort for that. After we solved that, some of us looked at
No Clue Crossword, but we didn't figure out how it worked. We thought it
might have been words that appear in a crossword solver when you
[entered "No clue"](https://www.wordplays.com/crossword-solver/no-clue)
as the clue, but that didn't seem very good, and we ended up backsolving
it.

After that, the next puzzle I did major work on was Food Court. The main
thing this puzzle taught me was that I was horribly out of practice on
probability - these were definitely questions I would have solved without
issue if I was back in undergrad. I got an answer for one, then started
transcribing the probabilities into code to compute the steady state of the
Markov chain. Someone else found an online tool for it, but said "it's garbage,
it's only accurate to the hundredeths place". We tried the steady state
and the numbers didn't seem that good. Given how the puzzle worked, we
figured we needed to check our work. I loudly went around asking people
to help us do math, and was told three times that someone was on it. I
wasn't really listening (my mistake), and on the third time, they sat me
down and explained that

1. They knew someone who made Nationals of MATHCOUNTS.
2. They weren't doing Hunt, so it was okay for us to ask them for help.
3. This someone solved probability problems in their spare time for fun.
4. They were both very fast and very accurate.

About 30 minutes later, that person told us three of our answers were wrong.
We fixed those, reran the Markov chains, and saw that the answers
were all exact hundredths from $$0.01$$ to $$0.26$$, within $$10^-7$$ tolerance
(the error
coming purely from floating-point approximation). So, that was that.

Side note: One of the big lessons I've learned from Puzzles are Magic is
that you always want to check how robust your puzzle is to errors. Solvers
will always, always make errors in solving, even if your clues are 100%
unambiguous. So, if possible, you want to check how robust your puzzle is
to a few errors. The less robust it is, the more likely it is that solvers will
do 90% of the work on a puzzle and fail to finish. If your partials are bad,
it's common that a solver
will try many different incorrect extractions, rather than fixing their data
and trying the correct extraction again. Generally, this means you want
mechanisms that extract one letter at a time, rather than all at once, and
you should check your cluephrase looks promising if you randomly change some
of the letters.

Food Court isn't very robust...but not every puzzle can be made robust without
compromising its idea.
I like the core idea of "you solve a bunch of math problems that seed a Markov chain",
and I do think it's a good puzzle, it's just unfortunate that a consequence
of the design is that solvers either get almost all the letters or none of them.
I guess you just accept this and move on.

And now we come to Change Machine. Oh boy. I started working on this puzzle
because I was told there was a lot of mindless drudgery that needed to be done
to the spreadsheet, and I was too tired to do any real solving. It turned out the puzzle was all
about the Omnibus podcast, and everything had been IDed, but they had been
IDed independently. Now that the Omnibus connection had been found, the main
solvers wanted help arranging the movies and bible verses by Omnibus episode.

I was still confused, and at some point I said "Okay,
it's 3 AM and I'm very tired. I need you to give me idiot-proof instructions
for what you want me to do." Which they did, so props. After everything was
ordered, I suggested indexing the KJ number into the Bible verse (since KJ
was likely short for King James). Reading in episode order gave out
AD AMUSEMENT COMPANY IS KEY.

We were confused. During this process, one person had been looking through
the Ken Jennings subreddit, and discovered a Reddit post where someone
asked what the hell was up with the RIDE ENHANCERS COLLECTIVE? (Find the post)

At this, we had a mental breakdown. Was this seeded information from Left Out?
Was the AD COMPANY Reddit? WAS THIS ACTUALLY HOW WE WERE SUPPOSED TO SOLVE THE
PUZZLE? I started looking up the post history of the Redditor, to see if they
posted on other puzzle subreddits, but all I found were posts on r/teenagers
and other subreddits dating back 10 months ago. Meanwhile, we were applying
some left-over offset numbers to RIDE ENHHANCERS COLLECTIVE, which gave the
answer.

The mental breakdown continued, and after a bunch more of "WHAT DID WE JUST
DO AND WHY DID IT WORK", we figured out that RIDE ENHANCERS COLLECTIVE was
part of the Omnibus episode that came out the weekend of Mystery Hunt. We
concluded that we had probably skipped a bunch of steps.
Reading the
solution, it turns out we skipped every cluephrase except the last one,
so thank you, Omnibus fans. Your confusion about the RIDE ENHANCERS COLLECTIVE
was not in vain.

With that done, I decided to start looking at Big Top Carnival puzzles. I didn't
contribute much to any of them, until someone said, "Hey, so all our answers are
Kentucky Derby horses". We piled onto the meta and had \*T\*R\*D\*R\*, which
we guessed was "something RIDER". Noticing that horse names had decently unique
enumerations, we asked if anyone was working on a puzzle with given answer lengths.
The group working on Weakest Carouselink said they had (4 4). (They had all
the chains, but were missing extraction.) One person found PINK STAR as a horse
option, and someone else proposed PINK SLIP. The people working on Weakest
Carouselink said "that seems bad", and I pointed out it was thematic to
Weakest Link (you get fired), so we called it in and it was right. That gave
us \*S\*T\*R\*D\*R\*, and within 30 seconds we went from that to
"STIRRUP?" to "STIRRUP DRAMA!" to "AHHHHHH WE SOLVED A META WITH 5 OUT OF 12 ANSWERS".

The true backsolve masters were all asleep at this time, but we had 7 puzzles
to backsolve, of course those of us awake were going to try. We got 3 of them in the next hour,
got stuck on the rest, and left it to others to finish up as we went back
to the YesterdayLand meta.

Sometime earlier that night, I had transcribed the blanks, their arrangement, and the
colors into the meta spreadsheet, and made guesses about how I wanted the
puzzle to work. After someone got the modernized answer break-in, I explained
how I felt it should work, and we started filling in letters. I had DUBSTEP for
modernized disco, which was okay. Then we tried EDM MUSIC, which was worse.
Then someone noticed that we could do ELECTRONIC DANCE MUSIC which freed up
the 7-long spot for PORNHUB, and after a brief "oh no they went there", we
got to the READ UNDER COLOR NUMBERS cluephrase. We didn't have enough answers
to get the meta, but I was getting pretty tired and decided to head back for
the night.

After I woke up, I caught up on what had happened.

* The remaining Big Top Carnival puzzles had been backsolved.
* YesterdayLand's meta was solved.
* We had the emoji a-ha for for Creative Picture Studios.
* We had unlocked Safari Adventure.

I ended up contributing the most to Safari Adventure, which is to be
expected - it was a really big round. For regular puzzles, I worked
on Golden Wolf (figured out the Gashly kids a-ha), Lion (finishing one of
the final logic puzzles), and Sheep (looking up Mega Man characters,
pointing out all the last words were 11 letters long, and spending an
hour *not* indexing by game number until someone else tried it and solved
the puzzle.) I also worked on Snake, where we got IAMB from *A*B, guessed
TROCHEES just in case, then got PACES from PACESA (we had some errors that
we guessed through).

I didn't work on Hyena, but there is a fun story for it. At one point,
the group working on it was convinced an answer was the letters in CAM,
permuted in some order, but they weren't sure what. They decided that, well
there were only 6 permutations, so they tried all 6 and got it. They then
got the letters SRT, in some order, and tried 4 of the 6 permutations,
before stopping out of fear of answer locks. During the Hunt, we thought
the answer locks were round-wide, and they didn't want to lock out other
Safari puzzles. When we backsolved it later, they were upset to learn it
was one of the 2 permutations of SRT they hadn't tried.

In the middle of Safari Adventure, we unlocked First You Visit..., which
was really funny, because there was a cascade of groans across each room
as people discovered the puzzle. Out of Puzzle Traumatic Stress Disorder,
no one solved the puzzle and we ended up backsvoling it.

For Safari metas, I looked at a few. In The Cubs
Scout, my incredibly-minor baseball knowledge helped a bit. In Zeus, I
looked up the animals, but didn't get much further. In Sam, I figured
out the stars-and-stripes idea, but didn't get the every-other trick.
We initially thought the Tiger would be a regular puzzle that was part of
5 metas, which we would have to backsolve entirely. Once we got to a 6th meta
that needed Tiger, we figured out that it was probably the metameta. The
Safari metas were getting solved pretty fast, and not every meta solver
noted what backsolve answer was left over, so a few of us decided to make
a Tiger tracking spreadsheet, to figure out what Tiger answers we had,
what we wanted to backsolve, and how each Safari meta worked. When
the Safari Adventure metameta unlocked, we transferred our data into that
sheet, and while doing so someone got the Tyger Tyger a-ha, which just
left finishing enough Safari metas to extract.

I haven't talked about the PennyPass system yet.
In this Hunt, we would
occasionally get PennyPasses, which could be used to unlock a puzzle in
any round you had unlocked.
I thought this was a neat choose-your-own-unlock-adventure, without the
downsides of 2018's experiment. In 2018, teams chose which round to unlock,
which was cool, but also meant that you might randomly pick the hardest round
instead of the easiest one, and the organizers had to be prepared for every
possible in-person interaction as soon as teams finished the intro round. It
hasn't come back yet, and I don't think it should.

Our PennyPass strategy
was to optimize for the most open puzzles at once (the width of the hunt).
In each round, solving one puzzle unlocked one other puzzle in that round.
So, solving within a round either kept your width constant, or decreased your
width if you had run out of puzzles to unlock in that round. The only way
to increase width was to unlock new rounds, or use PennyPasses. Our logic
was that we should always use PennyPasses in the most recently unlocked
round, because that round would have the fewest solves, and it would therefore
give a +1 width increase for the longest period of time.

We had one PennyPass left, that would expire in an hour, and the newest round
was Cascade Park. We had actually unlocked all regular puzzles in every previous
round by that point, so the question was whether to use it in Cascade Park now,
or to wait an hour to see if we could solve 10 puzzles and unlock Cactus Canyon
before the pass expired. It seemed really unlikely we'd solve 10 puzzles in
an hour, so we spent it on Cascade Park, and nothing happened.
