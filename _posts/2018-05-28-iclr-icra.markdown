---
layout: post
title:  "ICLR 2018 and ICRA 2018"
date:   2018-05-27 15:38:00 -0700
---

In the span of just under a month, I attended two conferences,
[ICLR 2018](https://iclr.cc/) (a deep learning conference), and
[ICRA 2018](https://icra2018.org/) (a robotics conference). I intended
to write a summary of ICLR right after attending, but got busy. I'm
less busy now, which presents a nice opportunity - a compare and contrast
between the two different conferences.

\* \* \*
{: .centered }

First off, it's shocking how short my memory for conferences is.
I have already forgotten almost everything from ICLR, and I'm reconstructing
my experience from scattered poster pictures and notes. None of this is
surprising, but the problem is that if you're reconstructing things from
notes, then the reconstruction quality depends on how sleepy I was when
I took the notes.

For me, the TL;DR of ICLR is that **adversarial learning continues to be
a big thing.** Now, GANs have been popular for a few years, but I'm casting
a wide umbrella here - this also includes adversarial examples, agents competing
against one another, and general minimax optimization.

This is probably just selection bias, because I like adversarial learning a lot.
One way to describe a GAN is that the discriminator is learning an implicit
cost function for similarity in the dataset. From this abstract point-of-view,
using an adversarial approach lets you replace a fixed cost function with a
learned cost function. This makes your problem more complicated, but the advantage
is that any advances in optimization improve both your ability to learn cost
functions and your ability to minimize those learned costs. At some tipping
point, this will outperform whatever fixed cost you can think of.

From an even more abstract view, this touches on
the power of expressive, optimizable function families (like neural nets).
Minimax optimization has been around for ages. The new thing is that
deep learning enables learning cost functions on high-dimensional data, like
images. But there are plenty of other things we could try to replace with
learned methods, and the long-term promise of deep learning is that it's
expressive enough that it *could* replace even more parts of the learning
process.

There's been a few articles (Pearl) about how a lot of deep learning concerns itself
with curve fitting (function approximation), and how this doesn't encompass all
of intelligence. I mostly with this perspective, but it also looks like you can
convert a lot of useful problems to curve-fitting problems.

I do worry a bit about this research trend for robustness reasons.
My intuition is that adversarial methods have more variance in performance,
because the alternating minimization makes your learning dynamics a lot less
predictable. Now, this isn't a deal breaker. It just depends
on the mean performance of adversarial methods. If they work a lot better on average,
then they'll outperform other methods on average, even if there's variance.

SUPER TERRIBLE PLOT?

That was enough of a tangent about the research. From an *organizational*
perspective, I liked that there were so many poster sessions at ICLR. This is
the first time I've gone to ICLR, my previous ML conference was NIPS, and NIPS
is just getting ridiculously large. Checking every poster at NIPS doesn't feel
doable. Checking every poster at ICLR felt possible (albeit ambitious). I also
appreciated that corporate recuriting didn't feel as ridiculous as it felt at
NIPS - companies gave out swag, but not especially ridiculous swag. At NIPS
companies were giving out fidget spinners. At ICLR, the weirdest thing I got was
a pair of socks.

Papers I noted as interesting or wanted to follow-up on later:

* Intrinsic Motivation Self Play
* Robust Adversarial Inverse RL
* Policy Optimization by Genetic Distillation
* Bayesian Optimization and HYperband
* The Intrinsic Dimension of Objective Landscapes
* Eigenoption Discovery Eigenpurposes as Intrinc Rewward
* Self-Ensembling for Visual Domain Adaptation
* To TD or not to TD
* Hypergradient optimization
* Action Selection Biasing, Knowledge GAin Estimates, exmploration MDP

\* \* \*
{: .centered }

In contrast, ICRA 2018 was quite different. This was my first robotics
conference. I started research as an ML person first, so my interests are more
on the learning-for-control side, rather than the make-new-robots side. As much
as possible, I'd like to treat real-world hardware as an abstraction, without
much care for how things are implemented, as long as I can request control
and have it executed with some reliability. (Somewhere, a roboticist weeps.)

This meant that I was both unfamiliar with a lot of topics, and less of the
research was interesting to me.

Despite this, I think it was good that I went. People at ICLR are entirely
sold that deep learning is cool, interesting, and is going to continue to
be both those things. People are ICRA were less certain.

There were certainly deep learning papers. Basically every perception paper I
saw was using CNNs in one way or another, because CNNs work. But right now, it's
still unclear whether deep learning for *control* will work. I think it should,
but it hasn't proven itself enough times.
The field is still at a point where people can
snark that deep learning is just a fad, and the pendulum will swing back soon.
As someone pretty all-in on ML, it was good to see that perspective.

I'd guess that the difference in mindset comes because people are focusing more
on getting robots to work, rather than on the algorithms used to get there.
Despite being a research conference, there was a sense of practicality about
the whole thing. Sometimes, a paper will use weird hacks that only make sense
for their robot. But real hardware is hard! It's unsatisfying, but understandable.

It was also interesting to see a bit more emphasis on the consumer. Rodney
Brooks had a neat talk about the design decisions behind turning Roomba into
a product, pointing out that a couple hundreed dollars gives you very little
leeway for fancy sensors and hardware. (He also had a tangent rant about
HRI research, which felt a bit out of place, but hey, sometimes you have to
rant.)

I didn't see or hear anyone complain about having to use CNNs for perception.
It seemed like the field was perfectly willing to adopt deep learning for
other parts of learning, as soon as it proves itself to be worth it.

Additionally, from an RL side. I saw almost no papers about model-free RL.
Everyone doing RL seemed to be doing model-based RL, or a mix of model-based
and model-free RL, or learning from demonstrations. It all makes sense from
a data efficiency point of view, it was more that it was funny to see.

In general, there was less novelty and maturity on the machine learning front,
but again, this is mostly because ICRA is a robotics conference, and not all
roboticists do ML.

* Applying Async Deep Classifcation Networks and Gaming RL BASED MOtion Planners
* OptLayer - Practice Constrain Optimization
* Synthetically Trained NN for Learning HUman-REadable PLans
* Semantic Robo Programming for Goal-Directed Manipulaion
* Interactive Perception

