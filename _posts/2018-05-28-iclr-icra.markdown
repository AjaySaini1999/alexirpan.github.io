---
layout: post
title:  "Thoughts On ICLR 2018 and ICRA 2018"
date:   2018-05-27 15:38:00 -0700
---

In the span of just under a month, I attended two conferences,
[ICLR 2018](https://iclr.cc/) and
[ICRA 2018](https://icra2018.org/). The first is a deep learning conference,
and the second is a robotics conference. They were pretty different, and I
figured it would be neat to compare and contrast the two.

My memory for conferences is shockingly short, so this is all reconstructed
from notes and pictures I took of research posters. The problem with this
strategy is that the reconstruction quality depends on how sleepy I was,
and whether I remembered to take notes for something or not.


ICLR 2018
=======================================================================

From the research side, the TL;DR of ICLR was that adversarial learning
continues to be a big thing.

The elephant in the room is GANs. Generative adversarial networks have been
popular for a few years, but I'm casting a wide umbrella here, one that
includes adversarial examples, multiagent environments where agents compete,
and general minimax optimization problems of the form $$\min_x \max_y f(x, y)$$.

There's a good chance this is selection bias.
I like adversarial learning a lot.
One way to describe a GAN is that the discriminator is learning an implicit
cost function to help train the generator.
In an abstract sense, this adversarial approach lets you change from a
fixed, human defined cost function, to a learned cost function that can adapt
to the capabilities of whatever you're trying to learn. In the GAN case,
you have a dynamic cost over image generation. But in a learning-by-self-play
case, you get dynamic costs over learning good agent behavior.

This does make your problem more complicated. One advantage
is that if there are advances in optimization or modeling ability, it can
improve both your ability to learn cost functions and your ability to minimize
those learned costs. The hope is that you eventually hit a tipping point where
it's *worth* spending a bunch of time doing adversarial learning.

From an even more abstract view, this touches on
the power of expressive, optimizable function families, like neural nets.
Minimax optimization is not a new idea, it's been around for ages. The new thing
is that deep learning enables learning cost functions on high-dimensional data.

There are other parts of the learning process that could be replaced with
learned nets instead of human-defined behavior. Does it make sense to do this.
Well, *maybe*. We'll see.

There was a recent [Quanta article](https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/),
where Judea Pearl expressed his disappointment that deep learning was just
learning correlations and curve fitting, that this doesn't cover all of
intelligence, and that the next step for AI is to learn cause and effect and
do causal inference. I agree with this, but it's possible that if you
throw enough super-big neural nets into a big enough vat of optimization soup,
you could learn something that looks like causal inference, or whatever else you want to
count as intelligence. But now we're in somewhat-unfounded philosophy land,
so I'll stop here.

From an attendee perspective, I liked having a lot of poster sessions. This is
the first time I've gone to ICLR. My previous ML conference was NIPS, and NIPS
just feels ridiculously large. Checking every poster at NIPS doesn't feel doable.
Checking every poster at ICLR felt *possible*, although whether you'd actually
want to do so is questionable.

I also appreciated that corporate recuriting didn't feel as ridiculous as NIPS.
At NIPS, companies were giving out fidget spinners and slinkies, which was *unique*,
but the fact that companies needed to *come up with unique swag to stand out*
felt...strange. At ICLR, the weirdest thing I got was a pair of socks.

Papers I noted to follow-up on later:

* [Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play](https://openreview.net/forum?id=SkT5Yg-RZ)
* [Learning Robust Rewards with Adverserial Inverse Reinforcement Learning](https://openreview.net/forum?id=rkHywl-A-)
* [Policy Optimization by Genetic Distillation](https://openreview.net/forum?id=ByOnmlWC-)
* [Measuring the Intrinsic Dimension of Objective Landscapes](https://openreview.net/forum?id=ryup8-WCW)
* [Eigenoption Discovery Through the Deep Successor Representation](https://openreview.net/forum?id=Bk8ZcAxR-)
* [Self-Ensembling for Visual Domain Adaptation](https://openreview.net/forum?id=rkpoTaxA-)
* [TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning](https://openreview.net/forum?id=HyiAuyb0b)
* [Online Learning Rate Adaptation with Hypergradient Descent](https://openreview.net/forum?id=BkrsAzWAb)
* [DORA The Explorer: Directed Outreaching Reinforcement Action-Selection](https://openreview.net/forum?id=ry1arUgCW)
* [Learning to Multi-Task by Active Sampling](https://openreview.net/forum?id=B1nZ1weCZ)


ICRA 2018
================================================================================

ICRA 2018 was my first robotics conference. I wasn't sure what to expect. I
started research as an ML person, and then sort of fell into robotics on the
side, so my interests are closer to learning-for-control instead of
making-new-robots. My ideal setup is one where I can run models on a real-world
robot, but the details of the real-world hardware / low-level software stack
are an abstraction. (Somewhere, a roboticist weeps.)

This meant I was unfamiliar with a lot of the topics, so less of the conference
appealed to me. Still, there were plenty of learning papers, and I'm glad I
went.

From the research side, it was interesting to see how many RL papers there
were. It was also interesting to see that almost none of those papers used
purely model-free RL. One thing about ICRA is that your paper has a much, much
better chance of getting accepted if it runs on a real-world robot. That
forces you to care about data efficiency. I kept seeing "We combine model-free
reinforcement learning with X", where X was model-based RL, or learning from
human demonstrations, or learning from existing motion planning solutions,
and so on.

At a broader level, it felt like there was a sense of practicality about a lot
of the research. This being research, plenty of it was still very speculative,
but it felt like another consequence of having to work with real hardware. You
can't ignore inference time if you need to run your model in real time. You
can't ignore data efficiency if you need to collect it from a real robot.
It has to work, and the real world doesn't care about a lot of things.

This surprises a lot of ML people I talk to, but robotics hasn't fully embraced
ML the way that people at NIPS / ICLR / ICML have. For a lot of people,
machine learning is just a solution that may make sense. The impression I got
was that only a few people actively wanted ML to fail, and everyone else wanted
it to prove itself first. Every perception paper I saw used CNNs in one way
or another, but significantly fewer people were using deep learning for control,
because that's the part that's uncertain. It was good to hear comments from
people who see deep learning as just a fad (even if I don't agree!).

It was also interesting to see a bit more emphasis on the consumer. Rodney
Brooks had a neat talk about the design decisions behind turning Roomba into
a product, pointing out that a couple hundreed dollars gives you very little
leeway for fancy sensors and hardware. (He also had a tangent rant about
HRI research, which felt a bit out of place, but hey, sometimes you have to
rant.)

Papers I noted to follow-up on later:

* [Applying Asynchronous Deep Classification Network and Gaming Reinforcement Learning-Based Motion Planner to a Mobile Robot](http://ghryou.me/assets/pdf/ghryou_icra_2018.pdf)
* [OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World](https://arxiv.org/abs/1709.07643)
* [Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations](https://arxiv.org/abs/1805.07054)
* [Semantic Robot Programming for Goal-Directed Manipulation in Cluttered Scenes](https://www.youtube.com/watch?v=kOcdqUmXRRo)
* [Interactive Perception: Leveraging Action in Perception and Perception in Action](https://arxiv.org/abs/1604.03670)
